{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "XzzDWzK_K60H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batchsize\n",
        "epochs=3\n",
        "#parameter tuning:taring batchsize\n",
        "train_batch = 64#default value\n",
        "#train_batch = 128\n",
        "#train_batch = 512\n",
        "#train_batch = 1000\n",
        "test_batch = 1000\n",
        "#output a log for every 100 iterations\n",
        "interval_print = 100\n",
        "\n",
        "random_seed = 2022\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNTncr3ILd-r",
        "outputId": "a7cb2c7b-2768-475b-937d-3a2169453a7b"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcfb4873190>"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, parameter tuning happens to these parameters: Batch size, hidden size, dropout,and optimizer<br>\n",
        "batch size: 64 ,128, 512<br>\n",
        "hidden size:5,10,20<br>\n",
        "dropout : 0.3, 0.5,0.7<br>\n",
        "Optimizer: SGD,Adam,Adagrad<br>\n"
      ],
      "metadata": {
        "id": "3CGTX6SpNgg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset load\n",
        "#since the global mean is 0.1307 and std deviation is 0.3081, we normalize the MNIST dataset using these two values with the builtin Normalize function\n",
        "#load train data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=train_batch, shuffle=True)\n",
        "#load test data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=test_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "p00Cdg84Lfdf"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(test_loader)\n",
        "#get the batch index for the training\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "metadata": {
        "id": "kygcuC7TLkON"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "bFxQf1hGLpfO"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pytorch_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Pytorch_Net, self).__init__()\n",
        "        #parameter tuning , hidden size 5,10,20\n",
        "        self.input_hidden = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.hidden_output = nn.Conv2d(10, 20, kernel_size=5)#default value\n",
        "        # self.input_hidden = nn.Conv2d(1, 5, kernel_size=5)\n",
        "        # self.hidden_output = nn.Conv2d(5, 20, kernel_size=5)\n",
        "        # self.input_hidden  = nn.Conv2d(1, 20, kernel_size=5)\n",
        "        # self.hidden_output = nn.Conv2d(20, 20, kernel_size=5)\n",
        "\n",
        "        #dropout layer\n",
        "        self.dropout_layer = nn.Dropout2d()#p=0.5 default vakue\n",
        "        #self.conv2_drop = nn.Dropout2d(p=0.3)\n",
        "        #self.conv2_drop = nn.Dropout2d(p=0.7)\n",
        "        #fully connected layers\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #use 2*2 pool kernel\n",
        "        x = F.relu(F.max_pool2d(self.input_hidden(x), 2))\n",
        "        x = F.tanh(F.max_pool2d(self.dropout_layer(self.hidden_output(x)), 2))\n",
        "        #modify the shape\n",
        "        x = x.view(-1, 320)\n",
        "        #calculate through the fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "ucDKwKMNLsqb"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_net = Pytorch_Net()\n",
        "optimizer=optim.Adam(neural_net.parameters(),lr=0.01,betas=(0.9,0.999))#default value\n",
        "#optimizer = optim.SGD(neural_net.parameters(), lr=0.01,momentum=0.5)\n",
        "#optimizer=optim.Adagrad(neural_net.parameters(),lr=0.01,lr_decay=0)"
      ],
      "metadata": {
        "id": "LbX57ht5L8Pd"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_total = []\n",
        "train_iteration = []\n",
        "test_loss_total = []\n",
        "test_iteration = [i*len(train_loader.dataset) for i in range(epochs + 1)]"
      ],
      "metadata": {
        "id": "_Fp6-G-bL_Em"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  #let the network start training\n",
        "  neural_net.train()\n",
        "  correct = 0\n",
        "  #training for each batch\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    #initialize all gradient to zero\n",
        "    optimizer.zero_grad()\n",
        "    #get output\n",
        "    output = neural_net(data)\n",
        "    #calculate the loss function\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    optimizer.step()\n",
        "    #output an result for certain interval\n",
        "    if batch_idx % interval_print == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.0f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item(),100. * correct / (batch_idx * len(data))))\n",
        "      train_loss_total.append(loss.item())\n",
        "      train_iteration.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "  #print out overall training accuracy\n",
        "  print('\\nTrain set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "  correct, len(train_loader.dataset),\n",
        "  100. * correct / len(train_loader.dataset)))"
      ],
      "metadata": {
        "id": "gBGYtrgUMBwm"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  #set module with evaluation mode\n",
        "  neural_net.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():#disable the gradient calculation since it is the test phase, no further change should be made\n",
        "    for data, target in test_loader:\n",
        "      output = neural_net(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      #accumulate the predictions\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_loss_total.append(test_loss)\n",
        "  #print out test accuracy\n",
        "  print('\\nTest set: Avg. loss: {:.2f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "a4wuF0_-MR4i"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(n_epochs=epochs):#define how many runs to training\n",
        "    #test the initial accuracy\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train(epoch)\n",
        "        test()"
      ],
      "metadata": {
        "id": "gQ91yah5MXPb"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5vBG7oCVgNc",
        "outputId": "46173864-9384-48c5-8791-c9b48bd13367"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.357809\tAccuracy: inf\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.722148\tAccuracy: 61\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.372094\tAccuracy: 71\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.552096\tAccuracy: 74\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.389269\tAccuracy: 76\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.308666\tAccuracy: 78\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.375377\tAccuracy: 79\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.706982\tAccuracy: 80\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.190001\tAccuracy: 80\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.506243\tAccuracy: 81\n",
            "\n",
            "Train set: Accuracy: 48681/60000 (81%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.19, Accuracy: 9559/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.217066\tAccuracy: inf\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.642016\tAccuracy: 88\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.481078\tAccuracy: 87\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.821658\tAccuracy: 87\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.450156\tAccuracy: 87\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.312484\tAccuracy: 87\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.265387\tAccuracy: 87\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.624976\tAccuracy: 87\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.181982\tAccuracy: 87\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.333581\tAccuracy: 87\n",
            "\n",
            "Train set: Accuracy: 52120/60000 (87%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 0.20, Accuracy: 9566/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.324862\tAccuracy: inf\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.424257\tAccuracy: 88\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.284344\tAccuracy: 87\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.360881\tAccuracy: 87\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.088641\tAccuracy: 87\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.434072\tAccuracy: 87\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.231539\tAccuracy: 87\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.509435\tAccuracy: 87\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.571562\tAccuracy: 87\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.421134\tAccuracy: 87\n",
            "\n",
            "Train set: Accuracy: 52188/60000 (87%)\n",
            "\n",
            "\n",
            "Test set: Avg. loss: 0.18, Accuracy: 9614/10000 (96%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}